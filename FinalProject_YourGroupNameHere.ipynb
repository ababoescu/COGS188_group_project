{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Ana Maria Baboescu\n",
    "- Fatima Enriquez\n",
    "- Eric Lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables\n",
    "\n",
    "\n",
    "Create an Artificial Intelligence (AI) algorithm that successfully wins the game of chess in as few moves as possible and this would be a two player game (one player vs AI). The data that we are using is based on the performance of AI and their opponents from previous completed games. The manner in which we are measuring the data is by documenting the scores each player has at the end of the completed games. We are utilizing the data to help reinforce the AI system. Performance is measured by the type of pieces/the number of pieces that a player takes out from their opponent and the ability to checkmate the king piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "There has been ample research regarding the use of AI to solve problems. Due to the increase in popularity of online games such as chess, sudoku, and solitaire, more individuals are inclined to play them virtually. Having this virtual access was key, especially during the pandemic <a name=\"cite_2\"></a>[<sup>[2]</sup>](#cite_2). However, the concern for many is how to detect cheating. The European Online Championship details that it is paramount to keep the integrity of the game to the point where more than eight participants, in 2020, were deemed disqualified for utilizing aid <a name=\"cite_3\"></a>[<sup>[3]</sup>](#cite_3). In this manner, there is a desire for softwares to be able to detect cheating in an online game <a name=\"cite_1\"></a>[<sup>[1]</sup>](#cite_1). The use of AI in online chess matches makes it easier for the person cheating to win the game. While it is fascinating to imagine how a program can win such a strategic game, ethically, it is paramount that as a society we use AI as a learning tool. \n",
    "\n",
    "Nonetheless, the desire to solve problems and expand the realm of artificial intelligence has been around for decades. In one of the most infamous games of chess played by Garry Kasparov and Deep Blue, the machine won by one point <a name=\"cite_1\"></a>[<sup>[1]</sup>](#cite_1). Deep Blue is a software created by International Business Machines Corporation (IBM), which consisted of 32 processors and produced “high-speed computations in parallel”. Deep Blue was thus able to evaluate about 200 million chess positions per second and held a “processing speed of 11.38 billion floating-point operations per second” <a name=\"cite_4\"></a>[<sup>[4]</sup>](#cite_4).This breakthrough to be able to have a machine detect and think like a human is evolutionary to the point where the legendary match, where Deep Blue won was due to the computational build of the machine. This is because the machine has such a high processing speed and evaluation power <a name=\"cite_1\"></a>[<sup>[1]</sup>](#cite_1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    "\n",
    "\n",
    "One of the widely known games, Chess, is a game typically associated with strategy and skill with multiple different styles of playing/executing. Thus, the success of the player is determined by the manner in which both players move. This can frequently be quite difficult for beginners, because without AI, one would have to seek different skill-leveled individuals to build one's mastery of the game. However, with AI, each time the player plays the system, it would be different for the player due to the reinforcement learning of past games it has played including its experience with the current player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Detail how/where you obtained the data and cleaned it (if necessary)\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import chess.engine\n",
    "import chess.svg\n",
    "import random\n",
    "from math import log, sqrt, e, inf\n",
    "#from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# for the gif\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "depth = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 1 - Implementing the Node Class & Upper Confidence Bound\n",
    "\n",
    "Before implementing the Monte Carlo algorithm, we first created a Node class since we were specifically focused on implementing a Monte Carlo Tree Search. The reason for us implementing a Monte Carlo Tree Search is due to its main advantage of being able to operate effectively without prior knowledge over certain domains (exempting the general rules and termination states of the game) through discovering its own moves and learning through random plays leading to it providing the best probabilistic move given the current state of the game. Because of this it is widely used in game theory like chess, in this case.\n",
    "\n",
    "On top of creating the Node class for this algorithm, we’ve also implement an Upper Confidence Bound (UCB) which, according to a medium article by Ishaan Gupta on “Monte Carlo Tree Search Application on Chess”, helps in deciding which node to evaluate based maximizing the probability of winning from the given state. UCB follows the general equation:\n",
    "\n",
    "$$A_t=argmax_a(Qt(a) + c\\sqrt{\\frac{ln(t)}{N_t(a)}})$$\n",
    "\n",
    "which consists of two factors, exploitation and exploration.\n",
    "\n",
    "The exploitation factor, that is represented by $Qt(a)$, measures how successful the action (a) is whenever it is used. To put it simply, the higher the success rate of the exploitation the higher the UCB value is. The exploration factor, $c\\sqrt{\\frac{ln(t)}{N_t(a)}}$ explores the possible actions to take. The UCB factor is calculated in the ucb1 function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self):\n",
    "        self.state = chess.Board() # current position of board\n",
    "        self.children = set() # set of all possible states from legal action from current node\n",
    "        self.parent = None # parent node of current node\n",
    "        self.N = 0 # number of times parent node has been visited\n",
    "        self.n = 0 # number of times current node has been visited\n",
    "        self.v = 0 # exploitation factor of current node\n",
    "        self.ucb = 0 # Upper confidence bound\n",
    "    def __lt__(self, other):\n",
    "        return self.ucb < other.ucb\n",
    "\n",
    "def ucb1(curr_node):\n",
    "    ans = curr_node.v + 2 * (sqrt(log(curr_node.N + e + (10 ** -6))/(curr_node.n + (10 ** -10))))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_board(board):\n",
    "    piece_values = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 10,\n",
    "        chess.KING: 0\n",
    "    }\n",
    "    value = 0\n",
    "    for piece_type in piece_values:\n",
    "        value += len(board.pieces(piece_type, chess.WHITE)) * piece_values[piece_type]\n",
    "        value -= len(board.pieces(piece_type, chess.BLACK)) * piece_values[piece_type]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(curr_node, reward):\n",
    "    board = curr_node.state \n",
    "    depth = 0\n",
    "    captured_piece = None\n",
    "    while not board.is_game_over():\n",
    "        legal_moves = list(board.legal_moves)\n",
    "        move_weights = []\n",
    "        for move in legal_moves:\n",
    "            board.push(move)\n",
    "            move_weights.append(evaluate_board(board))\n",
    "            board.pop()\n",
    "        total_weight = sum(move_weights)\n",
    "        if total_weight == 0:\n",
    "            move = random.choice(legal_moves)\n",
    "        else:\n",
    "            probabilities = [weight / total_weight for weight in move_weights]\n",
    "            move = random.choices(legal_moves, probabilities)[0]\n",
    "        if board.is_capture(move):\n",
    "            if board.is_en_passant(move):\n",
    "                captured_piece = chess.PAWN\n",
    "            else:\n",
    "                captured_piece = board.piece_at(move.to_square).piece_type\n",
    "        if captured_piece is not None and depth == 0:\n",
    "            if captured_piece == chess.PAWN:\n",
    "                reward += 1\n",
    "            elif captured_piece == chess.KNIGHT:\n",
    "                reward += 3\n",
    "            elif captured_piece == chess.BISHOP:\n",
    "                reward += 3\n",
    "            elif captured_piece == chess.ROOK:\n",
    "                reward += 5\n",
    "            elif captured_piece == chess.QUEEN:\n",
    "                reward += 9\n",
    "        board.push(move)\n",
    "        depth += 1\n",
    "\n",
    "    if board.is_game_over():\n",
    "        result = board.result()\n",
    "        if result == '1-0':\n",
    "            return reward + 10\n",
    "        elif result == '0-1':\n",
    "            return reward - 10\n",
    "        else:\n",
    "            return reward\n",
    "    return rollout(curr_node, reward)\n",
    "    #return evaluate_board(board) / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(curr_node, white):\n",
    "    if len(curr_node.children) == 0:\n",
    "        return curr_node\n",
    "    max_ucb = -inf\n",
    "    if white:\n",
    "        sel_child = None\n",
    "        for i in curr_node.children:\n",
    "            tmp = ucb1(i)\n",
    "            if tmp > max_ucb:\n",
    "                max_ucb = tmp\n",
    "                sel_child = i\n",
    "        return expand(sel_child, 0)\n",
    "    else:\n",
    "        sel_child = None\n",
    "        min_ucb = inf\n",
    "        for i in curr_node.children:\n",
    "            tmp = ucb1(i)\n",
    "            if tmp < min_ucb:\n",
    "                min_ucb = tmp\n",
    "                sel_child = i\n",
    "        return expand(sel_child, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [] # list that stores rewards\n",
    "\n",
    "def rollback(curr_node, reward):\n",
    "    curr_node.n += 1\n",
    "    curr_node.v += reward\n",
    "    while curr_node.parent is not None:\n",
    "        curr_node.N += 1\n",
    "        curr_node = curr_node.parent\n",
    "    rewards.append(reward) # Append the reward to the list\n",
    "    return curr_node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts_pred(curr_node, over, white, iterations=5000): #updated iterations from 10 to 100\n",
    "    if over:\n",
    "        return -1\n",
    "    all_moves = [curr_node.state.san(i) for i in list(curr_node.state.legal_moves)]\n",
    "    map_state_move = dict()\n",
    "\n",
    "    for i in all_moves:\n",
    "        tmp_state = chess.Board(curr_node.state.fen())\n",
    "        tmp_state.push_san(i)\n",
    "        child = Node()\n",
    "        child.state = tmp_state\n",
    "        child.parent = curr_node\n",
    "        curr_node.children.add(child)\n",
    "        map_state_move[child] = i\n",
    "\n",
    "    while iterations > 0:\n",
    "        if white:\n",
    "            max_ucb = -inf\n",
    "            sel_child = None\n",
    "            for i in curr_node.children:\n",
    "                tmp = ucb1(i)\n",
    "                if tmp > max_ucb:\n",
    "                    max_ucb = tmp\n",
    "                    sel_child = i\n",
    "\n",
    "            ex_child = expand(sel_child, 0)\n",
    "            reward = rollout(ex_child, 0)\n",
    "            curr_node = rollback(ex_child, reward)\n",
    "            iterations -= 1\n",
    "        else:\n",
    "            min_ucb = inf\n",
    "            sel_child = None\n",
    "            for i in curr_node.children:\n",
    "                tmp = ucb1(i)\n",
    "                if tmp < min_ucb:\n",
    "                    min_ucb = tmp\n",
    "                    sel_child = i\n",
    "\n",
    "            ex_child = expand(sel_child, 1)\n",
    "            reward = rollout(ex_child)\n",
    "            curr_node = rollback(ex_child, reward)\n",
    "            iterations -= 1\n",
    "        \n",
    "        if white:\n",
    "            max_ucb = -inf\n",
    "            selected_move = ''\n",
    "            for i in curr_node.children:\n",
    "                tmp = ucb1(i)\n",
    "                if tmp > max_ucb:\n",
    "                    max_ucb = tmp\n",
    "                    selected_move = map_state_move[i]\n",
    "            return selected_move\n",
    "        else:\n",
    "            min_ucb = inf\n",
    "            selected_move = ''\n",
    "            for i in curr_node.children:\n",
    "                tmp = ucb1(i)\n",
    "                if tmp < min_ucb:\n",
    "                    min_ucb = tmp\n",
    "                    selected_move = map_state_move[i]\n",
    "            return selected_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomLegalMove(curr_node):\n",
    "    legal_moves = list(curr_node.state.legal_moves)\n",
    "    rand = random.randrange(len(legal_moves))\n",
    "    return board.san(legal_moves[rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main Function\n",
    "board = chess.Board()\n",
    "\n",
    "white = 1\n",
    "moves = 0\n",
    "pgn = []\n",
    "game = chess.pgn.Game()\n",
    "evalutations = []\n",
    "sm = 0\n",
    "cnt = 0\n",
    "\n",
    "# store each board state as an image\n",
    "board_states = []\n",
    "#root = Node()\n",
    "while not board.is_game_over():\n",
    "    if white == 1:\n",
    "        \n",
    "\n",
    "        root = Node()\n",
    "        root.state = board\n",
    "        result = mcts_pred(root, board.is_game_over(), white, iterations=500) # added in iterations = 100\n",
    "\n",
    "        board.push_san(result)\n",
    "\n",
    "        pgn.append(result)\n",
    "        white ^= 1 # allows to switch between 2 different states black and white\n",
    "\n",
    "        # Save the current board state\n",
    "        board_states.append(board.copy())\n",
    "        moves += 1\n",
    "    else:\n",
    "        \n",
    "        root = Node()\n",
    "        root.state = board\n",
    "        result = getRandomLegalMove(root)\n",
    "        board.push_san(result)\n",
    "        pgn.append(result)\n",
    "        white ^= 1 \n",
    "        board_states.append(board.copy())\n",
    "        moves += 1\n",
    "\n",
    "board_states.append(board.copy())\n",
    "\n",
    "print(board)\n",
    "print(' '.join(pgn))\n",
    "print()\n",
    "print(board.result())\n",
    "game.headers['Result'] = board.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 5 - Gif and Graphs\n",
    "\n",
    "Below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unicode \n",
    "pieces_unicode = {\n",
    "    \"P\": \"♙\", \"R\": \"♖\", \"N\": \"♘\", \"B\": \"♗\", \"Q\": \"♕\", \"K\": \"♔\",\n",
    "    \"p\": \"♟\", \"r\": \"♜\", \"n\": \"♞\", \"b\": \"♝\", \"q\": \"♛\", \"k\": \"♚\" \n",
    "}\n",
    "\n",
    "# Create animation using FuncAnimation (from L6)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def plot_board(board, ax):\n",
    "    ax.clear()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow([[1, 0] * 4, [0, 1] * 4] * 4, cmap='gray', alpha=0.3) # gray and white\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            piece_unicode = pieces_unicode[piece.symbol()]\n",
    "            ax.text(square % 8, 7 - square // 8, piece_unicode, fontsize=36, ha='center', va='center')\n",
    "\n",
    "def update(frame):\n",
    "    plot_board(board_states[frame], ax)\n",
    "\n",
    "animation = FuncAnimation(fig, update, frames=len(board_states), repeat=False)\n",
    "animation.save('chess_game_2.gif', writer='pillow', fps=3)\n",
    "plt.close(fig)\n",
    "\n",
    "cumulative_rewards = []\n",
    "sum = 0\n",
    "for val in rewards:\n",
    "    sum += val\n",
    "    cumulative_rewards.append(sum)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_rewards, marker='o')\n",
    "plt.title('Updating Rewards Over the Game')\n",
    "plt.xlabel('Move Number')\n",
    "plt.ylabel('Reward')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![winning chess game reward png](winning_reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chess_game gif](winning_game.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
